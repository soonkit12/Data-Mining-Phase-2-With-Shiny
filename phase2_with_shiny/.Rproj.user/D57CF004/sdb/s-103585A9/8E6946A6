{
    "collab_server" : "",
    "contents" : "#market basket analysis\n#load library\nlibrary(\"arules\")\nlibrary(\"arulesViz\")\n\n\n# 1.data cleaning and maniputations\n#read as dataframe\ndf <- read.csv(\"files/1000-out1.csv\", header = FALSE, sep = \";\")\n \n#check dataframe structure\nstr(df)\ndim(df)\n\n#check any duplicated or missing value\nany(duplicated(df))\nsum(is.na(df))\n               \n#since the dataset already in basket format with first column as a ordered unique \n#identifier for each transaction and 2nd column is the set of  items bought in \n#that transaction all the items bought at the same time in one row which needed \n#in finiteding association rules. we read dataset as trasanction\n               \n#2.read dataset as transaction\ntran1 <- read.transactions(\"files/1000-out1.csv\", format =\"basket\",  sep = \",\", rm.duplicates = TRUE, cols=1)\n\n#create vector for item names according item ID\nmyLabels <- c(\"Chocolate Cake\",\"Lemon Cake\", \"Almond Tart\", \"Apple Pie\",\"Apple Tart\",\n              \"Apricot Tart\", \"Berry Tart\", \"Blackberry Tart\", \"Blueberry Tart\",\"Chocolate Tart\", \n              \"Cherry Tart\", \"Lemon Tart\",\"Casino Cake\",\"Pecan Tart\", \"Ganache Cookie\",\n              \"Gongolais Cookie\", \"Raspberry Cookie\", \"Lemon Cookie\",\"Chocolate Meringue\",\"Vanilla Meringue\",\n              \"Marzipan Cookie\", \"Tuile Cookie\", \"Walnut Cookie\",\"Opera Cake\",\"Almond Croissant\", \n              \"Apple Croissant\", \"Apricot Croissant\", \"Cheese Croissant\", \"Chocolate Croissant\",\"Apricot Danish\",\n              \"Apple Danish\",\"Almond Twist\",\"Almond Bear Claw\", \"Blueberry Danish\",  \"Strawberry Cake\",\n              \"Lemon Lemonade\", \"Raspberry Lemonade\",\"Orange Juice\",\"Green Tea\",\"Bottled Water\",\n              \"Hot Coffee\",\"Chocolate Coffee\",\"Vanilla Frappuccino\", \"Cherry Soda\", \"Single Espresso\",\n              \"Truffle Cake\", \"Chocolate Eclair\", \"Coffee Eclair\", \"Vanilla Eclair\", \"Napoleon Cake\")\n\nmyLevel1 <- c(0:49)\n\n#label item name to tran1\nitemInfo(tran1) <- data.frame(labels = myLabels)\n\n#view transaction data in dataframe\nResults = as(tran1, \"data.frame\")\n\n#inspect the item label correctness\ninspect(aggregate(tran1, itemInfo(tran1)[[\"labels\"]])) \n \n#view summary\nsummary(tran1) \nstr(tran1) \n\n#inspect basket items for all transaction\ninspect(tran1) \n\n#inspect basket items for 3 transaction\ninspect(tran1[1:3]) \n\n#Graph to display top 5 items \n#Frequency of item appeared in each transaction\nitemFrequencyPlot(tran1, topN = 5, support = 0) \n\n#Graph item Frequency with min. support 10% \n#Item that appear more than (1000 * 0.1 = 100) times.\nitemFrequencyPlot(tran1, support= 0.1)\n\n#find association rule with default setting\ntran1rules0 <- apriori(tran1) \n \n#view total number of rules output from default setting\ntran1rules0\n               \n#run the apriori algorithm on the transactions by modify the default setting to\n#support(0.01)\n#confidence(0.5)\n#min length of rules(2)\ntran1rules <- apriori(\n                tran1,\n                parameter = list(\n                  sup = 0.01, \n                  conf = 0.5, \n                  minlen=2,\n                  target=\"rules\")\n                )\n\n#inspect rules find interesting rule with diff supp and conf until  \ninspect(sort(tran1rules, by=\"lift\"))\n\n#after inspect many parameter we found this interesting rule and we decide to choose this parameter\ntran1rules <- apriori(\n  tran1,\n  parameter = list(\n    sup = 0.03, \n    conf = 0.9, \n    minlen=2,\n    target=\"rules\")\n)\n\n#view total number of rules output from modified setting\ntran1rules\n \n#view summary tran1rules\nsummary(tran1rules)\n               \n#Print the association rules \ninspect(tran1rules)\na = as((tran1rules),\"data.frame\")\nView(a[\"rules\"])\n#view the sorted high chances rules item purchased by \"lift\" in order to find the high support & high confidence rule \ninspect(sort(tran1rules, by=\"lift\"))\n\n               \n#Plot a few graphs that can help to visualize the rules\nplot(tran1rules)\nplot(tran1rules,\"graph\")\nplot(tran1rules,\"grouped\")\nplot(tran1rules, method = \"grouped\", control = list(k = 5))\nplot(tran1rules, method=\"graph\", control=list(type=\"items\"))\nplot(tran1rules, method=\"paracoord\",  control=list(alpha=.5, reorder=TRUE))\n \n\n#3.Pruning Redundant Rules\nsubset.matrix <- is.subset(tran1rules, tran1rules)\nsubset.matrix[lower.tri(subset.matrix, diag = T)] <- NA\nredundant <- colSums(subset.matrix, na.rm=T) >=1\n\n#show redundant rules\nwhich(redundant)\n\n#remove redundant rules\nrules.pruned <- tran1rules[!redundant]\n\n#the most likely rules sort by confidence, support , lift  by executing the following code. to show client\nconf <-sort(rules.pruned, by=\"confidence\", decreasing=TRUE)\ninspect(conf)\nsupp <-sort(rules.pruned, by=\"support\", decreasing=TRUE)\ninspect(supp)\ninspect(sort(rules.pruned, by=\"lift\"))\n\n#plot rules with redundant rules removed\nplot(rules.pruned) \nplot(rules.pruned,\"graph\") \nplot(rules.pruned,\"grouped\") \nplot(rules.pruned, method = \"grouped\", control = list(k = 5)) \nplot(rules.pruned, method=\"graph\", control=list(type=\"items\")) \nplot(rules.pruned, method=\"paracoord\",  control=list(alpha=.5, reorder=TRUE))\n \n\n",
    "created" : 1484153386032.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1208575041",
    "id" : "8E6946A6",
    "lastKnownWriteTime" : 1484307031,
    "last_content_update" : 1484307031355,
    "path" : "~/R/Assignment/phase2/bakery.R",
    "project_path" : "bakery.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}