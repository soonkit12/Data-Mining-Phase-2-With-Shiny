"Hot Coffee","Chocolate Coffee","Vanilla Frappuccino", "Cherry Soda", "Single Espresso",
"Truffle Cake", "Chocolate Eclair", "Coffee Eclair", "Vanilla Eclair", "Napoleon Cake")
myLevel1 <- c(0:49)
itemInfo(tran1) <- data.frame(labels = myLabels)
Results = as(tran1, "data.frame")
inspect(aggregate(tran1, itemInfo(tran1)[["labels"]]))
summary(tran1)
str(tran1)
inspect(tran1)
inspect(tran1[1:3])
itemFrequencyPlot(tran1, topN = 5)
runApp()
Results = as(tran1, "data.frame")
View(Results)
runApp()
View(Results)
runApp()
Results = as(tran1[c("transactionID","items")], "data.frame")
View(Results[c("transactionID","items")])
runApp()
itemFrequencyPlot(tran1, topN = 5)
itemFrequency(tran1)
a <- itemFrequency(tran1)
a
str(a)
dim(a)
runApp()
runApp()
runApp()
itemFrequencyPlot(tran1, topN = 5, support = 0.1)
itemFrequencyPlot(tran1, topN = 5, support = 0)
runApp()
runApp()
runApp()
runApp()
devtools::source_url('https://raw.githubusercontent.com/brooksandrew/Rsenal/master/R/rules2df.R')
devtools::source_url('https://raw.githubusercontent.com/brooksandrew/Rsenal/master/R/bin.R')
arulesApp <- function (dataset, bin=T, vars=5, supp=0.1, conf=0.5) {
## binning numeric data
for(i in 1:ncol(dataset)) {
if(class(dataset[,i]) %in% c('numeric', 'integer')) dataset[,i] <- Rsenal::depthbin(dataset[,i], nbins=10)
}
## calling Shiny App
shinyApp(ui = shinyUI(pageWithSidebar(
headerPanel("Association Rules"),
sidebarPanel(
conditionalPanel(
condition = "input.samp=='Sample'",
numericInput("nrule", 'Number of Rules', 5), br()
),
conditionalPanel(
condition = "input.mytab=='graph'",
radioButtons('graphType', label='Graph Type', choices=c('itemsets','items'), inline=T), br()
),
conditionalPanel(
condition = "input.lhsv=='Subset'",
uiOutput("choose_lhs"), br()
),
conditionalPanel(
condition = "input.rhsv=='Subset'",
uiOutput("choose_rhs"), br()
),
conditionalPanel(
condition = "input.mytab=='grouped'",
sliderInput('k', label='Choose # of rule clusters', min=1, max=150, step=1, value=15), br()
),
conditionalPanel(
condition = "input.mytab %in%' c('grouped', 'graph', 'table', 'datatable', 'scatter', 'paracoord', 'matrix', 'itemFreq')",
radioButtons('samp', label='Sample', choices=c('All Rules', 'Sample'), inline=T), br(),
uiOutput("choose_columns"), br(),
sliderInput("supp", "Support:", min = 0, max = 1, value = supp , step = 1/10000), br(),
sliderInput("conf", "Confidence:", min = 0, max = 1, value = conf , step = 1/10000), br(),
selectInput('sort', label='Sorting Criteria:', choices = c('lift', 'confidence', 'support')), br(), br(),
numericInput("minL", "Min. items per set:", 2), br(),
numericInput("maxL", "Max. items per set::", 3), br(),
radioButtons('lhsv', label='LHS variables', choices=c('All', 'Subset')), br(),
radioButtons('rhsv', label='RHS variables', choices=c('All', 'Subset')), br(),
downloadButton('downloadData', 'Download Rules as CSV')
)
),
mainPanel(
tabsetPanel(id='mytab',
tabPanel('Grouped', value='grouped', plotOutput("groupedPlot", width='100%', height='100%')),
tabPanel('Graph', value='graph', plotOutput("graphPlot", width='100%', height='100%')),
tabPanel('Scatter', value='scatter', plotOutput("scatterPlot", width='100%', height='100%')),
tabPanel('Parallel Coordinates', value='paracoord', plotOutput("paracoordPlot", width='100%', height='100%')),
tabPanel('Matrix', value='matrix', plotOutput("matrixPlot", width='100%', height='100%')),
tabPanel('ItemFreq', value='itemFreq', plotOutput("itemFreqPlot", width='100%', height='100%')),
tabPanel('Table', value='table', verbatimTextOutput("rulesTable")),
tabPanel('Data Table', value='datatable', dataTableOutput("rulesDataTable"))
)
)
)),
server = function(input, output) {
output$choose_columns <- renderUI({
checkboxGroupInput("cols", "Choose variables:",
choices  = colnames(dataset),
selected = colnames(dataset)[1:vars])
})
output$choose_lhs <- renderUI({
checkboxGroupInput("colsLHS", "Choose LHS variables:",
choices  = input$cols,
selected = input$cols[1])
})
output$choose_rhs <- renderUI({
checkboxGroupInput("colsRHS", "Choose RHS variables:",
choices  = input$cols,
selected = input$cols[1])
})
## Extracting and Defining arules
rules <- reactive({
tr <- as(dataset[,input$cols], 'transactions')
arAll <- apriori(tr, parameter=list(support=input$supp, confidence=input$conf, minlen=input$minL, maxlen=input$maxL))
if(input$rhsv=='Subset' & input$lhsv!='Subset'){
varsR <- character()
for(i in 1:length(input$colsRHS)){
tmp <- with(dataset, paste(input$colsRHS[i], '=', levels(as.factor(get(input$colsRHS[i]))), sep=''))
varsR <- c(varsR, tmp)
}
ar <- subset(arAll, subset=rhs %in% varsR)
} else if(input$lhsv=='Subset' & input$rhsv!='Subset') {
varsL <- character()
for(i in 1:length(input$colsLHS)){
tmp <- with(dataset, paste(input$colsLHS[i], '=', levels(as.factor(get(input$colsLHS[i]))), sep=''))
varsL <- c(varsL, tmp)
}
ar <- subset(arAll, subset=lhs %in% varsL)
} else if(input$lhsv=='Subset' & input$rhsv=='Subset') {
varsL <- character()
for(i in 1:length(input$colsLHS)){
tmp <- with(dataset, paste(input$colsLHS[i], '=', levels(as.factor(get(input$colsLHS[i]))), sep=''))
varsL <- c(varsL, tmp)
}
varsR <- character()
for(i in 1:length(input$colsRHS)){
tmp <- with(dataset, paste(input$colsRHS[i], '=', levels(as.factor(get(input$colsRHS[i]))), sep=''))
varsR <- c(varsR, tmp)
}
ar <- subset(arAll, subset=lhs %in% varsL & rhs %in% varsR)
} else {
ar <- arAll
}
quality(ar)$conviction <- interestMeasure(ar, method='conviction', transactions=tr)
quality(ar)$hyperConfidence <- interestMeasure(ar, method='hyperConfidence', transactions=tr)
quality(ar)$cosine <- interestMeasure(ar, method='cosine', transactions=tr)
quality(ar)$chiSquare <- interestMeasure(ar, method='chiSquare', transactions=tr)
quality(ar)$coverage <- interestMeasure(ar, method='coverage', transactions=tr)
quality(ar)$doc <- interestMeasure(ar, method='doc', transactions=tr)
quality(ar)$gini <- interestMeasure(ar, method='gini', transactions=tr)
quality(ar)$hyperLift <- interestMeasure(ar, method='hyperLift', transactions=tr)
ar
})
# Rule length
nR <- reactive({
nRule <- ifelse(input$samp == 'All Rules', length(rules()), input$nrule)
})
## Grouped Plot #########################
output$groupedPlot <- renderPlot({
ar <- rules()
plot(sort(ar, by=input$sort)[1:nR()], method='grouped', control=list(k=input$k))
}, height=800, width=800)
## Graph Plot ##########################
output$graphPlot <- renderPlot({
ar <- rules()
plot(sort(ar, by=input$sort)[1:nR()], method='graph', control=list(type=input$graphType))
}, height=800, width=800)
## Scatter Plot ##########################
output$scatterPlot <- renderPlot({
ar <- rules()
plot(sort(ar, by=input$sort)[1:nR()], method='scatterplot')
}, height=800, width=800)
## Parallel Coordinates Plot ###################
output$paracoordPlot <- renderPlot({
ar <- rules()
plot(sort(ar, by=input$sort)[1:nR()], method='paracoord')
}, height=800, width=800)
## Matrix Plot ###################
output$matrixPlot <- renderPlot({
ar <- rules()
plot(sort(ar, by=input$sort)[1:nR()], method='matrix', control=list(reorder=T))
}, height=800, width=800)
## Item Frequency Plot ##########################
output$itemFreqPlot <- renderPlot({
trans <- as(dataset[,input$cols], 'transactions')
itemFrequencyPlot(trans)
}, height=800, width=800)
## Rules Data Table ##########################
output$rulesDataTable <- renderDataTable({
ar <- rules()
rulesdt <- rules2df(ar)
rulesdt
})
## Rules Printed ########################
output$rulesTable <- renderPrint({
#hack to disply results... make sure this match line above!!
#ar <- apriori(dataset[,input$cols], parameter=list(support=input$supp, confidence=input$conf, minlen=input$minL, maxlen=input$maxL))
ar <- rules()
inspect(sort(ar, by=input$sort))
})
## Download data to csv ########################
output$downloadData <- downloadHandler(
filename = 'arules_data.csv',
content = function(file) {
write.csv(rules2df(rules()), file)
}
)
}
)
}
#market basket analysis
#load library
library("arules")
library("arulesViz")
# 1.data cleaning and maniputations
#read as dataframe
df <- read.csv("files/1000-out1.csv", header = FALSE, sep = ";")
#check dataframe structure
str(df)
dim(df)
#check any duplicated or missing value
any(duplicated(df))
sum(is.na(df))
#since the dataset already in basket format with first column as a ordered unique
#identifier for each transaction and 2nd column is the set of  items bought in
#that transaction all the items bought at the same time in one row which needed
#in finiteding association rules. we read dataset as trasanction
#2.read dataset as transaction
tran1 <- read.transactions("files/1000-out1.csv", format ="basket",  sep = ",", rm.duplicates = TRUE, cols=1)
#create vector for item names according item ID
myLabels <- c("Chocolate Cake","Lemon Cake", "Almond Tart", "Apple Pie","Apple Tart",
"Apricot Tart", "Berry Tart", "Blackberry Tart", "Blueberry Tart","Chocolate Tart",
"Cherry Tart", "Lemon Tart","Casino Cake","Pecan Tart", "Ganache Cookie",
"Gongolais Cookie", "Raspberry Cookie", "Lemon Cookie","Chocolate Meringue","Vanilla Meringue",
"Marzipan Cookie", "Tuile Cookie", "Walnut Cookie","Opera Cake","Almond Croissant",
"Apple Croissant", "Apricot Croissant", "Cheese Croissant", "Chocolate Croissant","Apricot Danish",
"Apple Danish","Almond Twist","Almond Bear Claw", "Blueberry Danish",  "Strawberry Cake",
"Lemon Lemonade", "Raspberry Lemonade","Orange Juice","Green Tea","Bottled Water",
"Hot Coffee","Chocolate Coffee","Vanilla Frappuccino", "Cherry Soda", "Single Espresso",
"Truffle Cake", "Chocolate Eclair", "Coffee Eclair", "Vanilla Eclair", "Napoleon Cake")
myLevel1 <- c(0:49)
#label item name to tran1
itemInfo(tran1) <- data.frame(labels = myLabels)
#view transaction data in dataframe
Results = as(tran1, "data.frame")
#inspect the item label correctness
inspect(aggregate(tran1, itemInfo(tran1)[["labels"]]))
#view summary
summary(tran1)
str(tran1)
#inspect basket items for all transaction
inspect(tran1)
#inspect basket items for 3 transaction
inspect(tran1[1:3])
#Graph to display top 5 items
#Frequency of item appeared in each transaction
itemFrequencyPlot(tran1, topN = 5, support = 0)
#Graph item Frequency with min. support 10%
#Item that appear more than (1000 * 0.1 = 100) times.
itemFrequencyPlot(tran1, support= 0.1)
#find association rule with default setting
tran1rules0 <- apriori(tran1)
#view total number of rules output from default setting
tran1rules0
#run the apriori algorithm on the transactions by modify the default setting to
#support(0.01)
#confidence(0.5)
#min length of rules(2)
tran1rules <- apriori(
tran1,
parameter = list(
sup = 0.01,
conf = 0.5,
minlen=2,
target="rules")
)
#view total number of rules output from modified setting
tran1rules
#view summary tran1rules
summary(tran1rules)
#Print the association rules
inspect(tran1rules)
# a = as((tran1rules),"data.frame")
#view the sorted high chances rules item purchased by "lift" in order to find the high support & high confidence rule
inspect(sort(tran1rules, by="lift"))
#Plot a few graphs that can help to visualize the rules
plot(tran1rules)
plot(tran1rules,"graph")
plot(tran1rules,"grouped")
plot(tran1rules, method = "grouped", control = list(k = 5))
plot(tran1rules, method="graph", control=list(type="items"))
plot(tran1rules, method="paracoord",  control=list(alpha=.5, reorder=TRUE))
#3.Pruning Redundant Rules
subset.matrix <- is.subset(tran1rules, tran1rules)
subset.matrix[lower.tri(subset.matrix, diag = T)] <- NA
redundant <- colSums(subset.matrix, na.rm=T) >=1
#show redundant rules
which(redundant)
#remove redundant rules
rules.pruned <- tran1rules[!redundant]
#the most likely rules sort by confidence, support , lift  by executing the following code. to show client
conf <-sort(rules.pruned, by="confidence", decreasing=TRUE)
inspect(conf)
supp <-sort(rules.pruned, by="support", decreasing=TRUE)
inspect(supp)
inspect(sort(rules.pruned, by="lift"))
#plot rules with redundant rules removed
plot(rules.pruned)
plot(rules.pruned,"graph")
plot(rules.pruned,"grouped")
plot(rules.pruned, method = "grouped", control = list(k = 5))
plot(rules.pruned, method="graph", control=list(type="items"))
plot(rules.pruned, method="paracoord",  control=list(alpha=.5, reorder=TRUE))
shiny::runApp()
if(require("DT")==FALSE){install.packages("DT")}
library(DT)
if(require("ggplot2")==FALSE){install.packages("ggplot2")}
library(ggplot2)
if(require("Amelia")==FALSE){install.packages("Amelia")}
library(Amelia)
if(require("arules")==FALSE){install.packages("arules")}
library(arules)
if(require("arulesViz")==FALSE){install.packages("arulesViz")}
library(arulesViz)
tran1 <- read.transactions("files/1000-out1.csv", format ="basket",  sep = ",", rm.duplicates = TRUE, cols=1)
myLabels <- c("Chocolate Cake","Lemon Cake", "Almond Tart", "Apple Pie","Apple Tart",
"Apricot Tart", "Berry Tart", "Blackberry Tart", "Blueberry Tart","Chocolate Tart",
"Cherry Tart", "Lemon Tart","Casino Cake","Pecan Tart", "Ganache Cookie",
"Gongolais Cookie", "Raspberry Cookie", "Lemon Cookie","Chocolate Meringue","Vanilla Meringue",
"Marzipan Cookie", "Tuile Cookie", "Walnut Cookie","Opera Cake","Almond Croissant",
"Apple Croissant", "Apricot Croissant", "Cheese Croissant", "Chocolate Croissant","Apricot Danish",
"Apple Danish","Almond Twist","Almond Bear Claw", "Blueberry Danish",  "Strawberry Cake",
"Lemon Lemonade", "Raspberry Lemonade","Orange Juice","Green Tea","Bottled Water",
"Hot Coffee","Chocolate Coffee","Vanilla Frappuccino", "Cherry Soda", "Single Espresso",
"Truffle Cake", "Chocolate Eclair", "Coffee Eclair", "Vanilla Eclair", "Napoleon Cake")
itemInfo(tran1) <- data.frame(labels = myLabels)
itemdata = as(tran1, "data.frame")
itemdata <- itemdata[c("transactionID","items")]
itemslist <- matrix(c(0:9,"Chocolate Cake","Lemon Cake", "Casino Cake","Opera Cake","Strawberry Cake","Truffle Cake", "Chocolate Eclair", "Coffee Eclair", "Vanilla Eclair", "Napoleon Cake",
10:19,"Almond Tart", "Apple Pie","Apple Tart","Apricot Tart", "Berry Tart", "Blackberry Tart", "Blueberry Tart","Chocolate Tart","Cherry Tart", "Lemon Tart",
20:29,"Pecan Tart", "Ganache Cookie","Gongolais Cookie", "Raspberry Cookie", "Lemon Cookie","Chocolate Meringue","Vanilla Meringue","Marzipan Cookie", "Tuile Cookie", "Walnut Cookie",
30:39,"Almond Croissant","Apple Croissant", "Apricot Croissant", "Cheese Croissant", "Chocolate Croissant","Apricot Danish","Apple Danish","Almond Twist","Almond Bear Claw", "Blueberry Danish",
40:49,"Lemonade", "Raspberry Lemonade","Orange Juice","Green Tea","Bottled Water","Hot Coffee","Chocolate Coffee","Vanilla Frappuccino", "Cherry Soda", "Single Espresso"), ncol = 10)
colnames(itemslist) <- c("Item ID","Item Name","Item ID","Item Name","Item ID","Item Name","Item ID","Item Name","Item ID","Item Name")
server <- function(input, output) {
#Render Table
#Item List
output$itemsTable <- renderTable(
itemslist,
width = "auto",
align = "c"
)
#Item Dataset
output$itemsDataset <- renderDataTable(itemdata)
#Render Plot
#Item Frequency
output$itemFeqPlot <- renderPrint(
itemFrequency(tran1)
)
output$feq_click_info <- renderPrint({
str(input$feq_plot_click)
})
output$feq_hover_info <- renderPrint({
str(input$feq_plot_hover)
})
}
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
tran1 <- read.transactions("files/1000-out1.csv", format ="basket",  sep = ",", rm.duplicates = TRUE, cols=1)
runApp()
getwd()
runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
#market basket analysis
#load library
library("arules")
library("arulesViz")
# 1.data cleaning and maniputations
#read as dataframe
df <- read.csv("files/1000-out1.csv", header = FALSE, sep = ";")
#check dataframe structure
str(df)
dim(df)
#check any duplicated or missing value
any(duplicated(df))
sum(is.na(df))
#since the dataset already in basket format with first column as a ordered unique
#identifier for each transaction and 2nd column is the set of  items bought in
#that transaction all the items bought at the same time in one row which needed
#in finiteding association rules. we read dataset as trasanction
#2.read dataset as transaction
tran1 <- read.transactions("files/1000-out1.csv", format ="basket",  sep = ",", rm.duplicates = TRUE, cols=1)
#create vector for item names according item ID
myLabels <- c("Chocolate Cake","Lemon Cake", "Almond Tart", "Apple Pie","Apple Tart",
"Apricot Tart", "Berry Tart", "Blackberry Tart", "Blueberry Tart","Chocolate Tart",
"Cherry Tart", "Lemon Tart","Casino Cake","Pecan Tart", "Ganache Cookie",
"Gongolais Cookie", "Raspberry Cookie", "Lemon Cookie","Chocolate Meringue","Vanilla Meringue",
"Marzipan Cookie", "Tuile Cookie", "Walnut Cookie","Opera Cake","Almond Croissant",
"Apple Croissant", "Apricot Croissant", "Cheese Croissant", "Chocolate Croissant","Apricot Danish",
"Apple Danish","Almond Twist","Almond Bear Claw", "Blueberry Danish",  "Strawberry Cake",
"Lemon Lemonade", "Raspberry Lemonade","Orange Juice","Green Tea","Bottled Water",
"Hot Coffee","Chocolate Coffee","Vanilla Frappuccino", "Cherry Soda", "Single Espresso",
"Truffle Cake", "Chocolate Eclair", "Coffee Eclair", "Vanilla Eclair", "Napoleon Cake")
myLevel1 <- c(0:49)
#label item name to tran1
itemInfo(tran1) <- data.frame(labels = myLabels)
#view transaction data in dataframe
Results = as(tran1, "data.frame")
#inspect the item label correctness
inspect(aggregate(tran1, itemInfo(tran1)[["labels"]]))
#view summary
summary(tran1)
str(tran1)
#inspect basket items for all transaction
inspect(tran1)
#inspect basket items for 3 transaction
inspect(tran1[1:3])
#Graph to display top 5 items
#Frequency of item appeared in each transaction
itemFrequencyPlot(tran1, topN = 5, support = 0)
#Graph item Frequency with min. support 10%
#Item that appear more than (1000 * 0.1 = 100) times.
itemFrequencyPlot(tran1, support= 0.1)
#find association rule with default setting
tran1rules0 <- apriori(tran1)
#view total number of rules output from default setting
tran1rules0
#run the apriori algorithm on the transactions by modify the default setting to
#support(0.01)
#confidence(0.5)
#min length of rules(2)
tran1rules <- apriori(
tran1,
parameter = list(
sup = 0.01,
conf = 0.5,
minlen=2,
target="rules")
)
#view total number of rules output from modified setting
tran1rules
#view summary tran1rules
summary(tran1rules)
#Print the association rules
inspect(tran1rules)
# a = as((tran1rules),"data.frame")
#view the sorted high chances rules item purchased by "lift" in order to find the high support & high confidence rule
inspect(sort(tran1rules, by="lift"))
#Plot a few graphs that can help to visualize the rules
plot(tran1rules)
plot(tran1rules,"graph")
plot(tran1rules,"grouped")
plot(tran1rules, method = "grouped", control = list(k = 5))
plot(tran1rules, method="graph", control=list(type="items"))
plot(tran1rules, method="paracoord",  control=list(alpha=.5, reorder=TRUE))
#3.Pruning Redundant Rules
subset.matrix <- is.subset(tran1rules, tran1rules)
subset.matrix[lower.tri(subset.matrix, diag = T)] <- NA
redundant <- colSums(subset.matrix, na.rm=T) >=1
#show redundant rules
which(redundant)
#remove redundant rules
rules.pruned <- tran1rules[!redundant]
#the most likely rules sort by confidence, support , lift  by executing the following code. to show client
conf <-sort(rules.pruned, by="confidence", decreasing=TRUE)
inspect(conf)
supp <-sort(rules.pruned, by="support", decreasing=TRUE)
inspect(supp)
inspect(sort(rules.pruned, by="lift"))
#plot rules with redundant rules removed
plot(rules.pruned)
plot(rules.pruned,"graph")
plot(rules.pruned,"grouped")
plot(rules.pruned, method = "grouped", control = list(k = 5))
plot(rules.pruned, method="graph", control=list(type="items"))
plot(rules.pruned, method="paracoord",  control=list(alpha=.5, reorder=TRUE))
runApp()
tran1rules
runApp()
a = as((tran1rules),"data.frame")
a
View(a)
View(a["rules"])
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
inspect(rules.pruned)
runApp()
